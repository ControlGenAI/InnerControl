<!DOCTYPE html>
<style>
  .container .hero-body .title.is-3 {
    margin-top: 10px !important; /* 减小标题距离顶部的间隔 */
  }
  .container .hero-body .subtitle {
    margin-bottom: 0 !important; /* 减小上文与Abstract之间的间隔 */
  }
</style>


<html>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js" integrity="sha384-R2lNHWtz1w8Q1b4Hp0SoQALQU35nOp2zP0WlO2hhVxpu4cr5Zg6H1V6YwD+f+Ch8" crossorigin="anonymous"></script>
<head>
  <meta charset="utf-8" />
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description"
    content="Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling." />

  <meta name="keywords"
    content="Conditional Image Generation, Uncertainty Learning" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>
    Ctrl-U | Project Page
  </title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" />
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

  <link rel="stylesheet" href="static/css/bulma.min.css" />
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="static/css/index.css" />
  <link rel="stylesheet" href="https://unpkg.com/beerslider/dist/BeerSlider.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title">
              Ctrl-U: Robust Conditional Image Generation<br> via Uncertainty-aware Reward Modeling
            </h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=NLPMoeAAAAAJ/">Guiyu Zhang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://c7w.tech/about/">Huan-ang Gao</a><sup>2</sup>,</span>
              <span class="author-block">
                Zijian Jiang<sup class="">2</sup>,</span>
              </span>
              <!-- <br> -->
              <span class="author-block">
                <a href="https://sites.google.com/view/fromandto" target="_blank" class="">Hao Zhao</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.zdzheng.xyz/" target="_blank" class="">Zhedong Zheng</a><sup>†1</sup>
              </span>
            </div>
            <!-- a margin of 0.5em -->
            <div style="margin: 0.5em;"></div>
            <div class="is-size-5 publication-authors">
              <span class="author-block is-size-5">
                <span class="author-block"><sup>1</sup> Faculty of Science and Technology, University of Macau<br>
                <span class="author-block"><sup>2</sup> Institute for AI Industry Research (AIR), Tsinghua University</span><br>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://blank" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://blank" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://blank" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js" crossorigin="anonymous"></script>


  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- Image with zero margin at the bottom -->
        <h2 class="title" style="text-align: center;">Motivation</h2>
        <img src="static/images/Motivation.png"
             class="interpolation-image"
             alt="Interpolate start reference image."/>
        <!-- Combined classes in the <h2> tag -->
        <h2 class="subtitle has-text-justified is-size-6" style=" font-size: 20px;">
          <b>Given a test image and the layout condition, we employ a diffusion model to generate new images by adding noise and then recovering from the noisy input.</b> (a) Ground-truth segmentation results with the category illustration. (b) Here we show the reward changes, \(\textit{i.e.}\), mIoU error, on newly generated images at different timesteps. The horizontal axis represents the current timestep <span>\(t\)</span> and the vertical axis shows the error, \( \textit{i.e.} \), 1-mIoU. As shown, even at <span>\(t = 0\)</span>, there are non-zero mIoU errors. As <span>\(t\)</span> increases, <strong>although the visual layout aligns with the condition, the reward model tends to increase the error,</strong> leading to the backpropagation of incorrect gradients.
        </h2>
      </div>
    </div>
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <!-- Reduced margin for Abstract title -->
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              In this paper, we focus on the task of conditional image generation, where an image is synthesized according to user instructions. The critical challenge underpinning this task is ensuring both the fidelity of the generated images and their semantic alignment with the provided conditions. To tackle this issue, previous studies have employed supervised perceptual losses derived from pre-trained models, \( \textit{i.e.} \), reward models, to enforce alignment between the condition and the generated result. However, we observe one inherent shortcoming: considering the diversity of synthesized images, the reward model usually provides inaccurate feedback when encountering newly generated data, which can undermine the training process. To address this limitation, we propose an uncertainty-aware reward modeling, called <b>Ctrl-U</b>, including uncertainty estimation and uncertainty-aware regularization, designed to reduce the adverse effects of imprecise feedback from the reward model. Given the inherent cognitive uncertainty within reward models, even images generated under identical conditions often result in a relatively large discrepancy in reward loss. Inspired by the observation, we explicitly leverage such prediction variance as an uncertainty indicator. Based on the uncertainty estimation, we regularize the model training by adaptively rectifying the reward. In particular, rewards with lower uncertainty receive higher loss weights, while those with higher uncertainty are given reduced weights to allow for larger variability. The proposed uncertainty regularization facilitates reward fine-tuning through consistency construction. Extensive experiments validate the effectiveness of our methodology in improving the controllability and generation quality, as well as its scalability across diverse conditional scenarios, including segmentation mask, edge, and depth conditions.
            </p>
          </div>
        </div>
    </div>    
    <div style="margin: 2em;"></div>
  <!-- End paper abstract -->
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Image with zero margin at the bottom -->
      <h2 class="title" style="text-align: center;">Method</h2>
      <img src="static/images/Method.png"
           class="interpolation-image"
           alt="Interpolate start reference image."/>
        <h2 class="subtitle has-text-justified is-size-6" style="margin-top: 5; font-size: 21px;">
          <b>Overall pipeline for our proposed method.</b> (a) Conditional Generation. Given text, source image <span>\(x_0\)</span>, and the conditional control <span>\(c\)</span>, we extract feature <span>\(z_0\)</span>, <span>\(f_t\)</span>, <span>\(f_c\)</span>, respectively. Then, we fine-tune the Diffusion model to generate two intermediate features for the image decoder. (b) Uncertainty Learning. Given the two features, we decode the two images, \( \textit{i.e.} \), <span>\(\hat{x}_0^1\)</span> and <span>\(\hat{x}_0^2\)</span>. Then we apply the reward model to obtain the two layout predictions <span>\(\hat{c}_1\)</span> and <span>\(\hat{c}_2\)</span>. We leverage the prediction discrepancy as the uncertainty indicator to rectify the original reward loss.
        </h2>
      </div>
    </div>
  <!-- End youtube video -->
    <div class="hero-body">
      <div class="container">
        <!-- Paper video. -->
        <h2 class="title is-3">Qualitative Results</h2> <!-- Results title, assuming it is left-aligned -->
        <div style="margin: 2em;"></div>
        <div class="container is-max-desktop">
          <div class="hero-body" style="padding: 10px 0;">
            <!-- Center-aligned title for better controllability and generation quality -->
            <h4 class="title is-4" style="margin-bottom: 5px; text-align: center;">Better Controllability and Generation Quality than Other Methods</h4>
            <img src="./static/images/visualization.png"
              class="interpolation-image"
              alt="Interpolate start reference image."/>
            <h4 class="subtitle has-text-centered is-size-6">
              <p>Qualitative comparisons with different conditional controls on unseen test images.</p>
            </h4>
          </div>
        </div>
  
        <div style="margin: 2em;"></div>
        <!-- Second Qualitative Results aligned with Results -->
        <h2 class="title is-3">Quantitative Results</h2> <!-- Results title, assuming it is left-aligned -->
        <div style="margin: 2em;"></div>
        <div class="container is-max-desktop">
          <div class="hero-body" style="padding: 10px 0;">
            <!-- Center-aligned title for better controllability and generation quality -->
            <h4 class="title is-4" style="margin-bottom: 5px; text-align: center;">Better Controllability than Other Methods</h4>
            <img src="./static/images/controllability.png"
              class="interpolation-image"
              alt="Interpolate start reference image."/>
              <h4 class="subtitle has-text-justified is-size-6" style="margin-top: 0; font-size: 21px;">
                <b>Controllability comparison under various conditional controls and datasets.</b> <span>\(\uparrow\)</span> denotes higher result is better, while <span>\(\downarrow\)</span> indicates lower is better. '-' signifies the absence of a publicly available model for testing. The best result in each column is marked <b>bold</b> and the second is <u>underlined</u>. We generate four groups of png images and report their average result to reduce random errors.
            </h4>

            <div style="margin: 1em;"></div>
            <h4 class="title is-4" style="margin-bottom: 5px; text-align: center;">Better Generation Quality than Other Methods</h4>
            <img src="./static/images/image_quality.png"
              class="interpolation-image"
              alt="Interpolate start reference image."/>
              <h4 class="subtitle has-text-justified is-size-6" style="margin-top: 0; font-size: 21px;">
                <b>FID (<span>\(\downarrow\)</span>) comparison under various conditional controls and datasets.</b> '-' signifies the absence of a publicly available model for testing. The best result in each column is marked <b>bold</b> and the second is <u>underlined</u>. We generate four groups of png images and report their average result to reduce random errors.
            </h4>
      </div>
    </div>

    <div style="margin: 2em;"></div>
    <h2 class="title is-3">More Visualization Results (GIF Demo)</h2> <!-- Results title, assuming it is left-aligned -->
    <div style="margin: 3.5em;"></div>
    <div class="container is-max-desktop">
      <div class="hero-body">
        <figure>
          <img src="./static/images/img_title.png" class="interpolation-image" alt="Interpolate start reference image."/>
          <!-- Center-align the title -->
          <h4 class="title is-4" style="text-align: center;">LineArt Edge</h4>
        </figure>
        <figure>
          <img src="./static/images/lineart.gif" class="interpolation-image" alt="Line art image"/>
          <h4 class="title is-4" style="text-align: center;">Depth Map</h4>
        </figure>
        <figure>
          <img src="./static/images/depth.gif" class="interpolation-image" alt="Depth image"/>
          <h4 class="title is-4" style="text-align: center;">Hed Edge</h4>
        </figure>
        <figure>
          <img src="./static/images/hed.gif" class="interpolation-image" alt="HED image"/>
          <h4 class="title is-4" style="text-align: center;">Segmentation Map</h4>
        </figure>
        <figure>
          <img src="./static/images/segmentation.gif" class="interpolation-image" alt="Segmentation image"/>
          <!-- Assuming there might be a title needed here as well, centered -->
        </figure>
      </div>
    </div>

    <div class="container is-max-desktop content" style="font-size: 16px;">
      <h2 class="title is-3">BibTeX</h2>
      If you find our work useful in your research, please consider citing:
      <pre style="font-size: 12px;"><code>@article{gao2024scp,
      title={SCP-Diff: Photo-Realistic Semantic Image Synthesis with Spatial-Categorical Joint Prior},
      author={Gao, Huan-ang and Gao, Mingju and Li, Jiaju and Li, Wenyi and Zhi, Rong and Tang, Hao and Zhao, Hao},
      journal={arXiv preprint arXiv:2403.09638},
      year={2024}
    }</code></pre>
    </div>
    
    <!--End BibTex citation -->
    
    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-10">
            <div class="content" style="font-size: 12px;"> <!-- Adjusted font size here -->
              <p>
                This page was built using the
                <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project
                  Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                You are free to borrow the of this website, we
                just ask that you link back to this page in the footer. <br />
                This website is licensed under a
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons
                  Attribution-ShareAlike 4.0 International
                  License</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
</section>
  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->
  <script src="https://unpkg.com/beerslider/dist/BeerSlider.js"></script>
  <script>
    new BeerSlider(document.getElementById('slider1'), { start: '40' });
    new BeerSlider(document.getElementById('slider2'), { start: '40' });
    new BeerSlider(document.getElementById('slider3'), { start: '40' });
    new BeerSlider(document.getElementById('slider4'), { start: '40' });
    new BeerSlider(document.getElementById('slider5'), { start: '40' });
    new BeerSlider(document.getElementById('slider6'), { start: '40' });
    new BeerSlider(document.getElementById('slider7'), { start: '40' });
    new BeerSlider(document.getElementById('slider8'), { start: '40' });
    new BeerSlider(document.getElementById('slider9'), { start: '40' });
    new BeerSlider(document.getElementById('slider10'), { start: '40' });
  </script>
</body>

</html>
